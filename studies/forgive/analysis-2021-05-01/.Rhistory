library(tidytext)
# set working directory
setwd("C:/Users/oakespar/Documents/forgive/analysis-2021-05-01")
Lexicon            <- read.csv('data/lexicon.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
Scripture_StrongsN <- read.csv('data/WebScraperOutput_NoStrongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
Scripture_StrongsY <- read.csv('data/WebScraperOutput_Strongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
View(Lexicon)
BibleBookOrder     <- read.csv('data/BibleBkOrder.csv', header = TRUE, na.strings = TRUE, encoding = 'UTF-8')
library(dplyr)
library(tidyr)
library(stringr)
load(stop_words)
library(stop_words)
data(stop_words)
View(Scripture_StrongsN)
Lexicon            <- read.csv('data/lexicon.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
BibleBookOrder     <- read.csv('data/BibleBkOrder.csv', header = TRUE, na.strings = TRUE, encoding = 'UTF-8')
Scripture_StrongsN <- read.csv('data/WebScraperOutput_NoStrongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
Scripture_StrongsY <- read.csv('data/WebScraperOutput_Strongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup()
Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(Text_String, word)
Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(word, Text_String)
Scripture_Tokens <- Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(word, Text_String)
Scripture_Tokens %>%
anti_join(stop_words)
Scripture_Tokens <- Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(word, Text_String) %>%
anti_join(stop_words)
TokensCount <- Scripture_Tokens %>%
count(word, sort = TRUE)
TokensCount
print(stop_words)
library(ggplot2)
Scripture_Tokens %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
Scripture_Tokens %>%
count(word, sort = TRUE) %>%
filter(n > 50) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
Scripture_Tokens <- Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(word, Text_String) #%>%
#anti_join(stop_words)
# Chart Unnested Tokens Count
Scripture_Tokens %>%
count(word, sort = TRUE) %>%
filter(n > 50) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
Scripture_Tokens <- Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(word, Text_String) %>%
anti_join(stop_words)
# Chart Unnested Tokens Count
Scripture_Tokens %>%
count(word, sort = TRUE) %>%
filter(n > 50) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
Scripture_Tokens
Scripture_Tokens %>% count(Book, word, sort = TRUE)
Scripture_Tokens %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n)
View(Lexicon)
Scripture_Tokens %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n) %>%
group_by(Book) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = Book)) %>%
geom_col(show.legend = FALSE) %>%
facet_wrap(~Book, scales = 'free') %>%
coord_flip()
# set working directory
setwd("C:/Users/oakespar/Documents/forgive/analysis-2021-05-01")
# invoke libraries
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
data(stop_words)
# read data
Lexicon            <- read.csv('data/lexicon.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
BibleBookOrder     <- read.csv('data/BibleBkOrder.csv', header = TRUE, na.strings = TRUE, encoding = 'UTF-8')
Scripture_StrongsN <- read.csv('data/WebScraperOutput_NoStrongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
Scripture_StrongsY <- read.csv('data/WebScraperOutput_Strongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
# Unnesting Tokens & Remove Stop Words
Scripture_Tokens <- Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(word, Text_String)
Scripture_Tokens_SWn <- Scripture_Tokens %>%
anti_join(stop_words)
Scripture_Tokens_SWy <- Scripture_Tokens %>%
join(stop_words)
# set working directory
setwd("C:/Users/oakespar/Documents/forgive/analysis-2021-05-01")
# invoke libraries
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
data(stop_words)
# read data
Lexicon            <- read.csv('data/lexicon.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
BibleBookOrder     <- read.csv('data/BibleBkOrder.csv', header = TRUE, na.strings = TRUE, encoding = 'UTF-8')
Scripture_StrongsN <- read.csv('data/WebScraperOutput_NoStrongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
Scripture_StrongsY <- read.csv('data/WebScraperOutput_Strongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
# Unnesting Tokens & Remove Stop Words
Scripture_Tokens <- Scripture_StrongsN %>%
group_by(Book) %>%
mutate(linenumber = row_number(), Chapter) %>%
ungroup() %>%
unnest_tokens(word, Text_String)
Scripture_Tokens_SWn <- Scripture_Tokens %>%
anti_join(stop_words)
Scripture_Tokens_SWy <- Scripture_Tokens %>%
semi_join(stop_words)
Scripture_Tokens_SWy
Scripture_Tokens_SWy %>% count(word, sort = TRUE)
Scripture_Tokens_SWy %>% unique(word) %>% sort()
Scripture_Tokens_SWy$word %>% unique() %>% sort()
Scripture_Tokens_SWn$word %>% unique() %>% sort() # list w/o stops words
Scripture_Tokens_SWn %>%
count(word, sort = TRUE) %>%
filter(n > 50) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
Scripture_Tokens_SWn %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n) %>%
group_by(Book) %>%
top_n(10) %>%
ungroup()
Scripture_Tokens_SWn %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n) %>%
group_by(Book) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = Book)) %>%
geom_col(show.legend = FALSE) %>%
facet_wrap(~Book, scales = 'free') %>%
coord_flip()
Scripture_Tokens_SWn_tfidf <- Scripture_Tokens_SWn %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n) %>%
group_by(Book) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf))
Scripture_Tokens_SWn_tfidf
Scripture_Tokens_SWn_tfidf$Book <- as.factor(Scripture_Tokens_SWn_tfidf$Book)
str(Scripture_Tokens_SWn_tfidf)
Scripture_Tokens_SWn_tfidf <- Scripture_Tokens_SWn %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n) %>%
group_by(Book) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf))
Scripture_Tokens_SWn_tfidf %>%
ggplot(aes(word, tf_idf, fill = factor(Book))) %>%
geom_col(show.legend = FALSE) %>%
facet_wrap(~Book, scales = 'free') %>%
coord_flip()
Scripture_Tokens_SWn_tfidf
Scripture_Tokens_SWn_tfidf %>%
ggplot(aes(word, tf_idf, fill = factor(Book))) +
geom_col(show.legend = FALSE) +
facet_wrap(~Book, scales = 'free') +
coord_flip()
View(BibleBookOrder)
View(BibleBookOrder)
# Add Testament Sections
?rep
c(rep('Old', 39), rep('New', 26))
# Add Testament Sections
Testaments <- as.factor(c(rep('Old', 39), rep('New', 26)))
BibleBookOrder$Testament <- Testament
# Add Testament Sections
Testaments <- as.factor(c(rep('Old', 39), rep('New', 26)))
BibleBookOrder$Testament <- Testament
BibleBookOrder$Testament <- Testaments
# Add Testament Sections
Testaments <- as.factor(c(rep('Old', 39), rep('New', 27)))
BibleBookOrder$Testament <- Testaments
BibleBookOrder$Order <- as.factor(BibleBookOrder$Order)
merge(x = Scripture_Tokens_SWn_tfidf,
y = BibleBookOrder,
by.x = Book,
by.y = Book)
merge(x = Scripture_Tokens_SWn_tfidf,
y = BibleBookOrder,
by.x = 'Book',
by.y = 'Book')
Scripture_WrdDocFreq <- merge(x = Scripture_Tokens_SWn_tfidf,
y = BibleBookOrder,
by.x = 'Book',
by.y = 'Book')
str(Scripture_WrdDocFreq)
BibleBookOrder     <- read.csv('data/BibleBkOrder.csv', header = TRUE, na.strings = TRUE, encoding = 'UTF-8')
Testaments <- c(rep('Old', 39), rep('New', 27))
BibleBookOrder$Testament <- Testaments
BibleBookOrder$Order <- as.factor(BibleBookOrder$Order)
Scripture_WrdDocFreq_Old <- Scripture_WrdDocFreq[Scripture_WrdDocFreq$Testament == 'Old',]
Scripture_WrdDocFreq_Old <- Scripture_WrdDocFreq[Scripture_WrdDocFreq$Testament == 'Old',]
Scripture_WrdDocFreq_Old
Scripture_WrdDocFreq_New <- Scripture_WrdDocFreq[Scripture_WrdDocFreq$Testament == 'New',]
dim(Scripture_WrdDocFreq_Old)
dim(Scripture_WrdDocFreq_New)
Scripture_TestSplit <- as.data.frame(
'Testament' = c('Old', 'New'),
'Rows' = c(
length(Scripture_WrdDocFreq_Old$Book),
length(Scripture_WrdDocFreq_New$Book)
)
)
data.frame(
'Testament' = c('Old', 'New'),
'Rows' = c(
length(Scripture_WrdDocFreq_Old$Book),
length(Scripture_WrdDocFreq_New$Book)
)
)
data.frame(
'Testament' = c('Old', 'New'),
'Rows' = c(
length(Scripture_WrdDocFreq_Old$Book),
length(Scripture_WrdDocFreq_New$Book)
)
)
Scripture_WrdDocFreq_Old %>%
ggplot(aes(word, tf_idf, fill = factor(Book, levels = unique(Order)))) +
geom_col(show.legend = FALSE) +
facet_wrap(~Book, scales = 'free') +
coord_flip()
Scripture_WrdDocFreq_Old %>%
ggplot(aes(word, tf_idf, fill = factor(Book))) +
geom_col(show.legend = FALSE) +
facet_wrap(~Book, scales = 'free') +
coord_flip()
Scripture_Tokens_SWn_tfidf <- Scripture_Tokens_SWn %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n) %>%
group_by(Book) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf))
Scripture_Tokens_SWn_tfidf_n10 <- Scripture_Tokens_SWn %>%
count(Book, word, sort = TRUE) %>%
bind_tf_idf(word, Book, n) %>%
group_by(Book) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf))
View(BibleBookOrder)
setwd("C:/Users/oakespar/Documents/forgive/analysis-2021-05-01")
# invoke libraries
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
data(stop_words)
# read data
Lexicon            <- read.csv('data/lexicon.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
BibleBookOrder     <- read.csv('data/BibleBkOrder.csv', header = TRUE, na.strings = TRUE, encoding = 'UTF-8')
Scripture_StrongsN <- read.csv('data/WebScraperOutput_NoStrongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
Scripture_StrongsY <- read.csv('data/WebScraperOutput_Strongs.csv', header = TRUE, sep = ',', encoding = 'UTF-8')
# merge bible book order to scriptures
Scripture_BblBkOrder <- merge(x = Scripture_StrongsN,  y = BibleBookOrder, by.x = 'Book', by.y = 'Book')
# Unnesting Tokens & Remove Stop Words
Scripture_Testmnt <- Scripture_BblBkOrder %>% group_by(Testament) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
Scripture_Section <- Scripture_BblBkOrder %>% group_by(Section) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
Scripture_Book <- Scripture_BblBkOrder %>% group_by(Book) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
# Unnesting Tokens & Remove Stop Words
Scripture_Testmnt <- Scripture_BblBkOrder %>% group_by(Testaments) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
Scripture_BblBkOrder
str(Scripture_BblBkOrder)
# Unnesting Tokens & Remove Stop Words
Scripture_Testmnt <- Scripture_BblBkOrder %>% group_by(Testmant) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
Scripture_Testmnt
str(Scripture_Testmnt)
colnames(Scripture_Testmnt)
colnames(BibleBookOrder)
BibleBookOrder[,1:4]
Scripture_BblBkOrder <- merge(x = Scripture_StrongsN,  y = BibleBookOrder[,1:4], by.x = 'Book', by.y = 'Book')
# Unnesting Tokens & Remove Stop Words
Scripture_Testmnt <- Scripture_BblBkOrder %>% group_by(Testmant) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
Scripture_Section <- Scripture_BblBkOrder %>% group_by(Section) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
Scripture_Book <- Scripture_BblBkOrder %>% group_by(Book) %>% mutate(linenumber = row_number(), Chapter) %>% ungroup() %>% unnest_tokens(word, Text_String)
Scripture_Testmnt
Scripture_Testmnt_SWn <- Scripture_Testmnt %>% anti_join(stop_words)
Scripture_Section_SWn <- Scripture_Section %>% anti_join(stop_words)
Scripture_Book_SWn    <- Scripture_Book %>% anti_join(stop_words)
Scripture_Testmnt_SWn %>%
count(word, sort = TRUE) %>% filter(n > 50) %>% mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) + geom_col() + labs(y = NULL)
colnames(Scripture_Testmnt_SWn)
Scripture_Testmnt_SWn %>%
count(word, sort = TRUE) %>% filter(n > 50) %>% mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) + geom_col() + labs(y = NULL) + facet_wrap(~Testmant, scales = 'free')
Scripture_Testmnt_SWn_tfidf <- Scripture_Testmnt_SWn %>%
count(Testmant, word, sort = TRUE) %>%
bind_tf_idf(word, Testmant, n) %>%
group_by(Testmant) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf))
Scripture_Testmnt_SWn_tfidf <- Scripture_Testmnt_SWn %>%
count(Testmant, word, sort = TRUE) %>%
bind_tf_idf(word, Testmant, n) %>%
group_by(Testmant) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf))
# tf-idf (top ten)
Scripture_Testmnt_SWn_tfidf_n10 <- Scripture_Testmnt_SWn %>%
count(Testmant, word, sort = TRUE) %>%
bind_tf_idf(word, Testmant, n) %>%
group_by(Testmant) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf))
Scripture_Testmnt_SWn_tfidf_n10 %>%
ggplot(aes(word, tf_idf, fill = factor(Testmant))) +
geom_col(show.legend = FALSE) +
facet_wrap(~Testmant, scales = 'free') +
coord_flip()
dim(Scripture_Testmnt_SWn_tfidf_n10)
Scripture_Testmnt_SWn_tfidf_n10
dim(Scripture_Testmnt_SWn_tfidf)
